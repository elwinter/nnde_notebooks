{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc01933-4390-476d-a1cf-b0b11ca74dc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d8cc2-025c-4db3-b758-0ee52a191c08",
   "metadata": {},
   "source": [
    "This notebook will examine the computational flow for computing gradients from a TF model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a49cd-1eea-4961-a094-f639351def79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb62bf-b451-4626-a548-2356090e3dba",
   "metadata": {},
   "source": [
    "Use a simple 1-hidden-layer network with a linear transfer function. Use a single input and a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fbc32b-47fe-4fbf-9088-c810715c8738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import standard Python modules.\n",
    "import datetime\n",
    "import importlib\n",
    "from itertools import repeat\n",
    "from math import exp\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Import 3rd-party modules.\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Import TensorFlow.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923802f2-dc57-4c16-8e7a-c0cdfbd4d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 64-bit math in TensorFlow.\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0025dc72-28c3-46e9-9e01-2e34501c6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(H, w0_range, u0_range, v0_range):\n",
    "    hidden_layer = tf.keras.layers.Dense(\n",
    "        units=H, use_bias=True,\n",
    "        # activation=tf.keras.activations.sigmoid,\n",
    "        activation=tf.keras.activations.linear,\n",
    "        kernel_initializer=tf.keras.initializers.RandomUniform(*w0_range),\n",
    "        bias_initializer=tf.keras.initializers.RandomUniform(*u0_range)\n",
    "    )\n",
    "    output_layer = tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        activation=tf.keras.activations.linear,\n",
    "        kernel_initializer=tf.keras.initializers.RandomUniform(*v0_range),\n",
    "        use_bias=False,\n",
    "    )\n",
    "    model = tf.keras.Sequential([hidden_layer, output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8afa12fa-516b-4f78-8316-341dbd04c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters.\n",
    "\n",
    "# Initial parameter ranges\n",
    "w0_range = [-0.1, 0.1]\n",
    "u0_range = [-0.1, 0.1]\n",
    "v0_range = [-0.1, 0.1]\n",
    "\n",
    "# Maximum number of training epochs.\n",
    "max_epochs = 1\n",
    "\n",
    "# Learning rate.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Number of hidden nodes.\n",
    "H = 2\n",
    "\n",
    "# Number of training points in each dimension.\n",
    "nx_train = 3\n",
    "\n",
    "# Random number generator seed.\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c9fa7b-2050-487e-bfc0-bf69e35d8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data.\n",
    "x_train = np.linspace(0, 1, nx_train)\n",
    "\n",
    "# Append an axis so the training data is 2-D, as expected by the model.\n",
    "# Then convert the training data to a Variable.\n",
    "x_train_v = tf.Variable(x_train[..., np.newaxis], name=\"x_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a35669fc-1d32-4a92-abc3-cbe0c60021c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0.\n",
      "x_train_v = <tf.Variable 'x_train:0' shape=(3, 1) dtype=float64, numpy=\n",
      "array([[0. ],\n",
      "       [0.5],\n",
      "       [1. ]])>\n",
      "N = tf.Tensor(\n",
      "[[0.00661098]\n",
      " [0.00466286]\n",
      " [0.00271474]], shape=(3, 1), dtype=float64)\n",
      "w = <tf.Variable 'dense_52/kernel:0' shape=(1, 2) dtype=float64, numpy=array([[-0.03283963, -0.04337479]])>\n",
      "u = <tf.Variable 'dense_52/bias:0' shape=(2,) dtype=float64, numpy=array([-0.01133743,  0.08387997])>\n",
      "v = <tf.Variable 'dense_53/kernel:0' shape=(2, 1) dtype=float64, numpy=\n",
      "array([[0.0123421 ],\n",
      "       [0.08048297]])>\n",
      "a = tf.Tensor(\n",
      "[[-0.01133743  0.08387997]\n",
      " [-0.02775725  0.06219257]\n",
      " [-0.04417707  0.04050517]], shape=(3, 2), dtype=float64)\n",
      "pjac = [<tf.Tensor: shape=(3, 1, 1, 2), dtype=float64, numpy=\n",
      "array([[[[0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.00617105, 0.04024149]]],\n",
      "\n",
      "\n",
      "       [[[0.0123421 , 0.08048297]]]])>, <tf.Tensor: shape=(3, 1, 2), dtype=float64, numpy=\n",
      "array([[[0.0123421 , 0.08048297]],\n",
      "\n",
      "       [[0.0123421 , 0.08048297]],\n",
      "\n",
      "       [[0.0123421 , 0.08048297]]])>, <tf.Tensor: shape=(3, 1, 2, 1), dtype=float64, numpy=\n",
      "array([[[[-0.01133743],\n",
      "         [ 0.08387997]]],\n",
      "\n",
      "\n",
      "       [[[-0.02775725],\n",
      "         [ 0.06219257]]],\n",
      "\n",
      "\n",
      "       [[[-0.04417707],\n",
      "         [ 0.04050517]]]])>]\n"
     ]
    }
   ],
   "source": [
    "# Set the random number seed for reproducibility.\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Build the model.\n",
    "model = build_model(H, w0_range, u0_range, v0_range)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"Starting epoch %s.\" % epoch)\n",
    "\n",
    "    # Run the forward pass.\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        print(\"x_train_v = %s\" % x_train_v)\n",
    "\n",
    "        # Compute the network output.\n",
    "        N = model(x_train_v)\n",
    "        print(\"N = %s\" % N)\n",
    "\n",
    "        # Examine the model parameters.\n",
    "        # w is shape (m, H).\n",
    "        print(\"w = %s\" % model.trainable_variables[0])\n",
    "        # u is shape (H,).\n",
    "        print(\"u = %s\" % model.trainable_variables[1])\n",
    "        # v is shape (H, 1).\n",
    "        print(\"v = %s\" % model.trainable_variables[2])\n",
    "\n",
    "        # Compute the output from the first layer.\n",
    "        # a is shape (n, H)\n",
    "        # a = x@w + u\n",
    "        a = model.layers[0](x_train_v)\n",
    "        print(\"a = %s\" % a)\n",
    "\n",
    "    # Compute the parameter gradients.\n",
    "    pjac = tape1.jacobian(N, model.trainable_variables)\n",
    "    print(\"pjac = %s\" % pjac)\n",
    "\n",
    "    # Compute the input gradients.\n",
    "    # xgrad = tape1.gradient(N, x_train_v)\n",
    "    # print(\"xgrad = %s\" % xgrad)\n",
    "\n",
    "    # Update the parameters for this epoch.\n",
    "#     optimizer.apply_gradients(zip(pgrad, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11042683-ee71-46f2-bea2-c548e1713e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
