{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b12829-e270-4b18-ab53-57cf055c1b3a",
   "metadata": {},
   "source": [
    "From `https://www.tensorflow.org/tutorials/keras/keras_tuner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1cb338-8079-49fa-8135-54de3b342f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec18e93a-a28d-46b6-8d75-b5aeb9395cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bad2e5b-76c6-4186-ac80-9aaee5edc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras-tuner-1.0.2.tar.gz (62 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras-tuner) (20.9)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras-tuner) (1.20.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras-tuner) (0.4.4)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.1-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras-tuner) (2.25.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras-tuner) (1.6.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ericw\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->keras-tuner) (2020.12.5)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: keras-tuner, future, terminaltables\n",
      "  Building wheel for keras-tuner (setup.py): started\n",
      "  Building wheel for keras-tuner (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-py3-none-any.whl size=78936 sha256=7c48f559dd35182f8ad772c4bdef8fd30fdbf5b2e24c23a726edd970a2d3f0a5\n",
      "  Stored in directory: c:\\users\\ericw\\appdata\\local\\pip\\cache\\wheels\\78\\e2\\80\\7fe373cad54ad22b06d0d6204cbc29cead9e69bb2680327775\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=445f6917840bd70cba0d7b1c25f1f0c29625ef71d42ff487eb9ed4d225fdc6c5\n",
      "  Stored in directory: c:\\users\\ericw\\appdata\\local\\pip\\cache\\wheels\\56\\b0\\fe\\4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for terminaltables (setup.py): started\n",
      "  Building wheel for terminaltables (setup.py): finished with status 'done'\n",
      "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=0a5c172c519e3e799cd23d133403a45fab9f75ed66a9067b5679f298e6ade0d5\n",
      "  Stored in directory: c:\\users\\ericw\\appdata\\local\\pip\\cache\\wheels\\ba\\ad\\c8\\2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
      "Successfully built keras-tuner future terminaltables\n",
      "Installing collected packages: threadpoolctl, joblib, tqdm, terminaltables, tabulate, scikit-learn, future, keras-tuner\n",
      "Successfully installed future-0.18.2 joblib-1.0.1 keras-tuner-1.0.2 scikit-learn-0.24.2 tabulate-0.8.9 terminaltables-3.1.0 threadpoolctl-2.1.0 tqdm-4.61.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88d7817-a332-4536-a83c-cdc0235c7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1bcd2ba-5879-4b7f-90ff-5e371bf5c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 7s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d5e918-d65f-4876-af71-a59c203650e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f2eaa2-6516-43fa-8238-29b578d0c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d64e24-45fb-4f68-8606-2e983a4a948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afef8207-1ec2-4272-a2ba-13392456c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b7cacd-f3e0-401f-9c96-e73bf8a4c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 27s]\n",
      "val_accuracy: 0.856083333492279\n",
      "\n",
      "Best val_accuracy So Far: 0.8851666450500488\n",
      "Total elapsed time: 00h 06m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 416 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1eefb9-be89-48d7-874c-a4bc4c65acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4948 - accuracy: 0.8247 - val_loss: 0.4056 - val_accuracy: 0.8545\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3711 - accuracy: 0.8637 - val_loss: 0.3750 - val_accuracy: 0.8652\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3312 - accuracy: 0.8786 - val_loss: 0.3570 - val_accuracy: 0.8705\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3083 - accuracy: 0.8860 - val_loss: 0.3333 - val_accuracy: 0.8784\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2889 - accuracy: 0.8937 - val_loss: 0.3321 - val_accuracy: 0.8802\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2725 - accuracy: 0.8981 - val_loss: 0.3241 - val_accuracy: 0.8823\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2567 - accuracy: 0.9042 - val_loss: 0.3282 - val_accuracy: 0.8821\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2445 - accuracy: 0.9088 - val_loss: 0.3240 - val_accuracy: 0.8857\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2338 - accuracy: 0.9123 - val_loss: 0.3349 - val_accuracy: 0.8861\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2256 - accuracy: 0.9149 - val_loss: 0.3325 - val_accuracy: 0.8881\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2172 - accuracy: 0.9181 - val_loss: 0.3065 - val_accuracy: 0.8933\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2077 - accuracy: 0.9217 - val_loss: 0.3285 - val_accuracy: 0.8915\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2006 - accuracy: 0.9241 - val_loss: 0.3294 - val_accuracy: 0.8900\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1933 - accuracy: 0.9272 - val_loss: 0.3371 - val_accuracy: 0.8848\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1847 - accuracy: 0.9303 - val_loss: 0.3524 - val_accuracy: 0.8838\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1798 - accuracy: 0.9327 - val_loss: 0.3276 - val_accuracy: 0.8936\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1727 - accuracy: 0.9344 - val_loss: 0.3455 - val_accuracy: 0.8904\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1665 - accuracy: 0.9381 - val_loss: 0.3403 - val_accuracy: 0.8932\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1595 - accuracy: 0.9400 - val_loss: 0.3456 - val_accuracy: 0.8942\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1555 - accuracy: 0.9420 - val_loss: 0.3554 - val_accuracy: 0.8917\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1525 - accuracy: 0.9425 - val_loss: 0.3454 - val_accuracy: 0.8966\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1463 - accuracy: 0.9457 - val_loss: 0.3635 - val_accuracy: 0.8919\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1422 - accuracy: 0.9458 - val_loss: 0.3724 - val_accuracy: 0.8942\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1384 - accuracy: 0.9483 - val_loss: 0.3442 - val_accuracy: 0.8946\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9499 - val_loss: 0.3889 - val_accuracy: 0.8901\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1305 - accuracy: 0.9511 - val_loss: 0.3983 - val_accuracy: 0.8918\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1257 - accuracy: 0.9523 - val_loss: 0.3927 - val_accuracy: 0.8943\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9541 - val_loss: 0.4127 - val_accuracy: 0.8918\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1195 - accuracy: 0.9549 - val_loss: 0.4279 - val_accuracy: 0.8867\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1184 - accuracy: 0.9551 - val_loss: 0.4161 - val_accuracy: 0.8890\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1150 - accuracy: 0.9563 - val_loss: 0.4306 - val_accuracy: 0.8943\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1105 - accuracy: 0.9578 - val_loss: 0.4663 - val_accuracy: 0.8883\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.4190 - val_accuracy: 0.8925\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1053 - accuracy: 0.9603 - val_loss: 0.4471 - val_accuracy: 0.8916\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1038 - accuracy: 0.9601 - val_loss: 0.4473 - val_accuracy: 0.8937\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9623 - val_loss: 0.4614 - val_accuracy: 0.8943\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9624 - val_loss: 0.4775 - val_accuracy: 0.8867\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0935 - accuracy: 0.9653 - val_loss: 0.4832 - val_accuracy: 0.8915\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9648 - val_loss: 0.4708 - val_accuracy: 0.8969\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0914 - accuracy: 0.9661 - val_loss: 0.4831 - val_accuracy: 0.8943\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9663 - val_loss: 0.5395 - val_accuracy: 0.8852\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9651 - val_loss: 0.4897 - val_accuracy: 0.8910\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9673 - val_loss: 0.4809 - val_accuracy: 0.8902\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9695 - val_loss: 0.4817 - val_accuracy: 0.8968\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9684 - val_loss: 0.5227 - val_accuracy: 0.8929\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9695 - val_loss: 0.4905 - val_accuracy: 0.8943\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0771 - accuracy: 0.9708 - val_loss: 0.5351 - val_accuracy: 0.8941\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0770 - accuracy: 0.9722 - val_loss: 0.5306 - val_accuracy: 0.8946\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9706 - val_loss: 0.5123 - val_accuracy: 0.8972\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 0.5126 - val_accuracy: 0.8930\n",
      "Best epoch: 49\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2158a371-0974-481a-9bad-fb2e330b7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4954 - accuracy: 0.8247 - val_loss: 0.4558 - val_accuracy: 0.8246\n",
      "Epoch 2/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3719 - accuracy: 0.8653 - val_loss: 0.3912 - val_accuracy: 0.8543\n",
      "Epoch 3/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3315 - accuracy: 0.8779 - val_loss: 0.3561 - val_accuracy: 0.8758\n",
      "Epoch 4/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3026 - accuracy: 0.8885 - val_loss: 0.3489 - val_accuracy: 0.8688\n",
      "Epoch 5/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2846 - accuracy: 0.8937 - val_loss: 0.3470 - val_accuracy: 0.8770\n",
      "Epoch 6/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2713 - accuracy: 0.8981 - val_loss: 0.3137 - val_accuracy: 0.8867\n",
      "Epoch 7/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2567 - accuracy: 0.9042 - val_loss: 0.3569 - val_accuracy: 0.8744\n",
      "Epoch 8/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2461 - accuracy: 0.9089 - val_loss: 0.3124 - val_accuracy: 0.8920\n",
      "Epoch 9/49\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2335 - accuracy: 0.9131 - val_loss: 0.3166 - val_accuracy: 0.8880\n",
      "Epoch 10/49\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2269 - accuracy: 0.9158 - val_loss: 0.3217 - val_accuracy: 0.8885\n",
      "Epoch 11/49\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2144 - accuracy: 0.9195 - val_loss: 0.3285 - val_accuracy: 0.8893\n",
      "Epoch 12/49\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2076 - accuracy: 0.9220 - val_loss: 0.3219 - val_accuracy: 0.8878\n",
      "Epoch 13/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2009 - accuracy: 0.9249 - val_loss: 0.3230 - val_accuracy: 0.8911\n",
      "Epoch 14/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1909 - accuracy: 0.9273 - val_loss: 0.3200 - val_accuracy: 0.8929\n",
      "Epoch 15/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1864 - accuracy: 0.9304 - val_loss: 0.3321 - val_accuracy: 0.8928\n",
      "Epoch 16/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1779 - accuracy: 0.9338 - val_loss: 0.3517 - val_accuracy: 0.8864\n",
      "Epoch 17/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1725 - accuracy: 0.9356 - val_loss: 0.3512 - val_accuracy: 0.8901\n",
      "Epoch 18/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1682 - accuracy: 0.9363 - val_loss: 0.3657 - val_accuracy: 0.8849\n",
      "Epoch 19/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1622 - accuracy: 0.9400 - val_loss: 0.3530 - val_accuracy: 0.8888\n",
      "Epoch 20/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1559 - accuracy: 0.9420 - val_loss: 0.3464 - val_accuracy: 0.8910\n",
      "Epoch 21/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1565 - accuracy: 0.9411 - val_loss: 0.3587 - val_accuracy: 0.8923\n",
      "Epoch 22/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1468 - accuracy: 0.9452 - val_loss: 0.3579 - val_accuracy: 0.8922\n",
      "Epoch 23/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1429 - accuracy: 0.9455 - val_loss: 0.3779 - val_accuracy: 0.8887\n",
      "Epoch 24/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1405 - accuracy: 0.9476 - val_loss: 0.3803 - val_accuracy: 0.8904\n",
      "Epoch 25/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1344 - accuracy: 0.9498 - val_loss: 0.3736 - val_accuracy: 0.8930\n",
      "Epoch 26/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1322 - accuracy: 0.9498 - val_loss: 0.3807 - val_accuracy: 0.8920\n",
      "Epoch 27/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1330 - accuracy: 0.9500 - val_loss: 0.3714 - val_accuracy: 0.8941\n",
      "Epoch 28/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1231 - accuracy: 0.9549 - val_loss: 0.3809 - val_accuracy: 0.8931\n",
      "Epoch 29/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1209 - accuracy: 0.9546 - val_loss: 0.3883 - val_accuracy: 0.8937\n",
      "Epoch 30/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1211 - accuracy: 0.9536 - val_loss: 0.4040 - val_accuracy: 0.8937\n",
      "Epoch 31/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1170 - accuracy: 0.9566 - val_loss: 0.4053 - val_accuracy: 0.8945\n",
      "Epoch 32/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1126 - accuracy: 0.9566 - val_loss: 0.4127 - val_accuracy: 0.8914\n",
      "Epoch 33/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1101 - accuracy: 0.9588 - val_loss: 0.4272 - val_accuracy: 0.8928\n",
      "Epoch 34/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1092 - accuracy: 0.9586 - val_loss: 0.4496 - val_accuracy: 0.8924\n",
      "Epoch 35/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1070 - accuracy: 0.9605 - val_loss: 0.4549 - val_accuracy: 0.8892\n",
      "Epoch 36/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1048 - accuracy: 0.9593 - val_loss: 0.4168 - val_accuracy: 0.8938\n",
      "Epoch 37/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0989 - accuracy: 0.9628 - val_loss: 0.4425 - val_accuracy: 0.8933\n",
      "Epoch 38/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0988 - accuracy: 0.9621 - val_loss: 0.4527 - val_accuracy: 0.8936\n",
      "Epoch 39/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0966 - accuracy: 0.9635 - val_loss: 0.4681 - val_accuracy: 0.8855\n",
      "Epoch 40/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0931 - accuracy: 0.9646 - val_loss: 0.4533 - val_accuracy: 0.8907\n",
      "Epoch 41/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0902 - accuracy: 0.9651 - val_loss: 0.4774 - val_accuracy: 0.8873\n",
      "Epoch 42/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0896 - accuracy: 0.9672 - val_loss: 0.4666 - val_accuracy: 0.8938\n",
      "Epoch 43/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0895 - accuracy: 0.9662 - val_loss: 0.5204 - val_accuracy: 0.8857\n",
      "Epoch 44/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.4763 - val_accuracy: 0.8936\n",
      "Epoch 45/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0834 - accuracy: 0.9690 - val_loss: 0.4943 - val_accuracy: 0.8905\n",
      "Epoch 46/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0851 - accuracy: 0.9677 - val_loss: 0.5121 - val_accuracy: 0.8892\n",
      "Epoch 47/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.4919 - val_accuracy: 0.8892\n",
      "Epoch 48/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.4919 - val_accuracy: 0.8965\n",
      "Epoch 49/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0794 - accuracy: 0.9703 - val_loss: 0.5289 - val_accuracy: 0.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b268a28c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636f7325-cf09-4396-aa78-984bdfdf5e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.8835\n",
      "[test loss, test accuracy]: [0.5958139896392822, 0.8834999799728394]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44671cb4-fdf9-4cd4-b145-ff958cc92c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
