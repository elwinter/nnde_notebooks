{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5169f6-efe8-487c-88a1-9f20541282d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python modules.\n",
    "import datetime\n",
    "import importlib\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Import 3rd-party modules.\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Import TensorFlow.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35241708-a05f-4642-8bf2-793fb5c6a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 64-bit math in TensorFlow.\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d73f1-7ca8-42c9-9eeb-b144af7e51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inlet conditions\n",
    "rho_0 = 1.08\n",
    "vx_0 = 1.2\n",
    "vy_0 = 0.01\n",
    "vz_0 = 0.5\n",
    "p_0 = 0.95\n",
    "bx_0 = 1/np.sqrt(np.pi)\n",
    "by_0 = 1.8/np.sqrt(np.pi)\n",
    "bz_0 = 1/np.sqrt(np.pi)\n",
    "\n",
    "# Outlet conditions\n",
    "rho_1 = 1.0\n",
    "vx_1 = 0.0\n",
    "vy_1 = 0.0\n",
    "vz_1 = 0.0\n",
    "p_1 = 1.0\n",
    "bx_1 = 1/np.sqrt(np.pi)\n",
    "by_1 = 2.0/np.sqrt(np.pi)\n",
    "bz_1 = 1/np.sqrt(np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a9029-12ab-4b00-9715-bd484c529766",
   "metadata": {},
   "source": [
    "# Solving with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775fe50-2915-45a7-be0f-9626078ea930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_system_information():\n",
    "    print(\"System report:\")\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"Host name: %s\" % platform.node())\n",
    "    print(\"OS: %s\" % platform.platform())\n",
    "    print(\"uname:\", platform.uname())\n",
    "    print(\"Python version: %s\" % sys.version)\n",
    "    print(\"Python build:\", platform.python_build())\n",
    "    print(\"Python compiler: %s\" % platform.python_compiler())\n",
    "    print(\"Python implementation: %s\" % platform.python_implementation())\n",
    "    # print(\"Python file: %s\" % __file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5108993-c34b-4665-8b34-eca840a2710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(path=None):\n",
    "    path_noext, ext = os.path.splitext(path)\n",
    "    output_dir = path_noext\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7d07f-be4d-4c51-8fcb-d9ad048c88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnde.math.trainingdata import create_training_grid2\n",
    "\n",
    "def create_training_data(*n_train):\n",
    "    x_train = np.array(create_training_grid2(*n_train))\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a172e-2e3b-436e-a8c2-30ec3a39686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(H, w0_range, u0_range, v0_range):\n",
    "    hidden_layer = tf.keras.layers.Dense(\n",
    "        units=H, use_bias=True,\n",
    "        activation=tf.keras.activations.sigmoid,\n",
    "        kernel_initializer=tf.keras.initializers.RandomUniform(*w0_range),\n",
    "        bias_initializer=tf.keras.initializers.RandomUniform(*u0_range)\n",
    "    )\n",
    "    output_layer = tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        activation=tf.keras.activations.linear,\n",
    "        kernel_initializer=tf.keras.initializers.RandomUniform(*v0_range),\n",
    "        use_bias=False,\n",
    "    )\n",
    "    model = tf.keras.Sequential([hidden_layer, output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c85ace-8b94-4371-a963-172448629e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_system_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603488d-9f36-4c11-9788-4b13bcf1b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the output directory.\n",
    "eq_name = \"1dmhd\"\n",
    "path = os.path.join(\".\", eq_name)\n",
    "output_dir = create_output_directory(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220421d2-169f-48ae-a3c7-ec5bc4e2ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters.\n",
    "\n",
    "# Training optimizer\n",
    "optimizer_name = \"Adam\"\n",
    "\n",
    "# Initial parameter ranges\n",
    "w0_range = [-0.1, 0.1]\n",
    "u0_range = [-0.1, 0.1]\n",
    "v0_range = [-0.1, 0.1]\n",
    "\n",
    "# Maximum number of training epochs.\n",
    "max_epochs = 1000\n",
    "\n",
    "# Learning rate.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Absolute tolerance for consecutive loss function values to indicate convergence.\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of hidden nodes.\n",
    "H = 10\n",
    "\n",
    "# Number of dimensions\n",
    "m = 2\n",
    "\n",
    "# Number of training points in each dimension.\n",
    "nx_train = 11\n",
    "nt_train = 11\n",
    "n_train = nx_train*nt_train\n",
    "\n",
    "# Number of validation points in each dimension.\n",
    "nx_val = 21\n",
    "nt_val = 21\n",
    "n_val = nx_val*nt_val\n",
    "\n",
    "# Random number generator seed.\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa423e4b-b35c-4e83-ab82-412d8d83d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the training data.\n",
    "xt_train = create_training_data(nx_train, nt_train)\n",
    "x_train = xt_train[::nt_train, 0]\n",
    "t_train = xt_train[:nt_train, 1]\n",
    "np.savetxt(os.path.join(output_dir,'xt_train.dat'), xt_train)\n",
    "\n",
    "# Create and save the validation data.\n",
    "xt_val = create_training_data(nx_val, nt_val)\n",
    "x_val = xt_val[::nt_val, 0]\n",
    "t_val = xt_val[:nt_val, 1]\n",
    "np.savetxt(os.path.join(output_dir, 'xt_val.dat'), xt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8621e73c-c912-470b-a22a-808b28007903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the differential equations using TensorFlow operations.\n",
    "\n",
    "@tf.function\n",
    "def pde1(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt):\n",
    "    G = tf.zeros(x.shape)\n",
    "    return G\n",
    "\n",
    "@tf.function\n",
    "def pde2(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt):\n",
    "    G = tf.zeros(x.shape)\n",
    "    return G\n",
    "\n",
    "@tf.function\n",
    "def pde3(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt):\n",
    "    G = tf.zeros(x.shape)\n",
    "    return G\n",
    "\n",
    "@tf.function\n",
    "def pde4(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt):\n",
    "    G = tf.zeros(x.shape)\n",
    "    return G\n",
    "\n",
    "@tf.function\n",
    "def pde5(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt):\n",
    "    G = tf.zeros(x.shape)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4979edb5-19bc-4e1e-87e9-4691e3ac1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trial functions.\n",
    "\n",
    "@tf.function\n",
    "def rho_trial(x, t, N):\n",
    "    A = (1 - x)*rho_0 + x*rho_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def vx_trial(x, t, N):\n",
    "    A = (1 - x)*vx_0 + x*vx_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def vy_trial(x, t, N):\n",
    "    A = (1 - x)*vy_0 + x*vy_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def vz_trial(x, t, N):\n",
    "    A = (1 - x)*vz_0 + x*vz_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def bx_trial(x, t, N):\n",
    "    A = (1 - x)*bx_0 + x*bx_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def by_trial(x, t, N):\n",
    "    A = (1 - x)*by_0 + x*by_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y\n",
    "\n",
    "@tf.function\n",
    "def bz_trial(x, t, N):\n",
    "    A = (1 - x)*bz_0 + x*bz_1\n",
    "    P = x*(1 - x)\n",
    "    Y = A + P*N[:, 0]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95dd6c43-e136-4755-a99f-ad0357f2e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: n_train = 121, H = 10, max_epochs = 1000, optimizer = Adam, learning_rate = 0.01\n",
      "Training started at 2021-12-21 20:38:58.575878\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['dense_336/kernel:0', 'dense_336/bias:0', 'dense_337/kernel:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_336/kernel:0' shape=(2, 10) dtype=float64, numpy=\narray([[-0.03283963, -0.04337479, -0.0333208 ,  0.08916026,  0.01477627,\n         0.03570686,  0.01561058, -0.02717073, -0.03789904,  0.03355774],\n       [-0.05238489,  0.06219781, -0.01221314, -0.0895774 , -0.01940561,\n        -0.02365936, -0.03380184, -0.03492679,  0.03708778, -0.03626765]])>), (None, <tf.Variable 'dense_336/bias:0' shape=(10,) dtype=float64, numpy=\narray([-0.01133743,  0.08387997, -0.06781313, -0.07689423,  0.05155497,\n       -0.08215367, -0.0969972 ,  0.07260706,  0.03820939,  0.09358523])>), (None, <tf.Variable 'dense_337/kernel:0' shape=(10, 1) dtype=float64, numpy=\narray([[ 0.0123421 ],\n       [ 0.08048297],\n       [-0.04861869],\n       [ 0.03526692],\n       [ 0.02936934],\n       [-0.08908385],\n       [ 0.01508242],\n       [ 0.08253389],\n       [ 0.00133063],\n       [ 0.0946394 ]])>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pl/hvfwp56s6ml6fwnq1mkcptdh0000gp/T/ipykernel_34618/1964942567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# Update the parameters for this epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0moptimizer_rho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgrad_rho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0moptimizer_vx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgrad_vx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_vx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0moptimizer_vy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgrad_vy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_vy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-3.8/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-3.8/lib/python3.8/site-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_336/kernel:0', 'dense_336/bias:0', 'dense_337/kernel:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_336/kernel:0' shape=(2, 10) dtype=float64, numpy=\narray([[-0.03283963, -0.04337479, -0.0333208 ,  0.08916026,  0.01477627,\n         0.03570686,  0.01561058, -0.02717073, -0.03789904,  0.03355774],\n       [-0.05238489,  0.06219781, -0.01221314, -0.0895774 , -0.01940561,\n        -0.02365936, -0.03380184, -0.03492679,  0.03708778, -0.03626765]])>), (None, <tf.Variable 'dense_336/bias:0' shape=(10,) dtype=float64, numpy=\narray([-0.01133743,  0.08387997, -0.06781313, -0.07689423,  0.05155497,\n       -0.08215367, -0.0969972 ,  0.07260706,  0.03820939,  0.09358523])>), (None, <tf.Variable 'dense_337/kernel:0' shape=(10, 1) dtype=float64, numpy=\narray([[ 0.0123421 ],\n       [ 0.08048297],\n       [-0.04861869],\n       [ 0.03526692],\n       [ 0.02936934],\n       [-0.08908385],\n       [ 0.01508242],\n       [ 0.08253389],\n       [ 0.00133063],\n       [ 0.0946394 ]])>))."
     ]
    }
   ],
   "source": [
    "# Build the models.\n",
    "model_rho = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_vx = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_vy = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_vz = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_bx = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_by = build_model(H, w0_range, u0_range, v0_range)\n",
    "model_bz = build_model(H, w0_range, u0_range, v0_range)\n",
    "\n",
    "# Create the optimizers.\n",
    "optimizer_rho = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_vx = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_vy = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_vz = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_bx = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_by = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer_bz = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Train the models.\n",
    "\n",
    "# Create history variables.\n",
    "losses1 = []\n",
    "losses2 = []\n",
    "losses3 = []\n",
    "losses4 = []\n",
    "losses5 = []\n",
    "losses = []\n",
    "phist_rho = []\n",
    "phist_vx = []\n",
    "phist_vy = []\n",
    "phist_vz = []\n",
    "phist_bx = []\n",
    "phist_by = []\n",
    "phist_bz = []\n",
    "\n",
    "# Set the random number seed for reproducibility.\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Rename the training data Variable (_v) for convenience, just for training.\n",
    "# shape (n_train, m)\n",
    "xt_train_var = tf.Variable(xt_train, name=\"xt_train\")\n",
    "xt = xt_train_var\n",
    "x = xt[:, 0]\n",
    "t = xt[:, 1]\n",
    "\n",
    "# Clear the convergence flag to start.\n",
    "converged = False\n",
    "\n",
    "print(\"Hyperparameters: n_train = %s, H = %s, max_epochs = %s, optimizer = %s, learning_rate = %s\"\n",
    "      % (n_train, H, max_epochs, optimizer_name, learning_rate))\n",
    "t_start = datetime.datetime.now()\n",
    "print(\"Training started at\", t_start)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    pass\n",
    "\n",
    "    # Run the forward pass.\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        with tf.GradientTape(persistent=True) as tape0:\n",
    "\n",
    "            # Compute the network outputs at the training points.\n",
    "            N_rho = model_rho(xt)\n",
    "            N_vx = model_vx(xt)\n",
    "            N_vy = model_vy(xt)\n",
    "            N_vz = model_vz(xt)\n",
    "            N_bx = model_bx(xt)\n",
    "            N_by = model_by(xt)\n",
    "            N_bz = model_bz(xt)\n",
    "\n",
    "            # Compute the trial solutions.\n",
    "            rho = rho_trial(x, t, N_rho)\n",
    "            vx = vx_trial(x, t, N_vx)\n",
    "            vy = vy_trial(x, t, N_vy)\n",
    "            vz = vz_trial(x, t, N_vz)\n",
    "            bx = bx_trial(x, t, N_bx)\n",
    "            by = by_trial(x, t, N_by)\n",
    "            bz = bz_trial(x, t, N_bz)\n",
    "\n",
    "        # Compute the gradients of the trial solutions wrt inputs.\n",
    "        del_rho = tape0.gradient(rho, xt)\n",
    "        drho_dx = del_rho[:, 0]\n",
    "        drho_dt = del_rho[:, 1]\n",
    "        del_vx = tape0.gradient(vx, xt)\n",
    "        dvx_dx = del_vx[:, 0]\n",
    "        dvx_dt = del_vx[:, 1]\n",
    "        del_vy = tape0.gradient(vy, xt)\n",
    "        dvy_dx = del_vy[:, 0]\n",
    "        dvy_dt = del_vy[:, 1]\n",
    "        del_vz = tape0.gradient(vz, xt)\n",
    "        dvz_dx = del_vz[:, 0]\n",
    "        dvz_dt = del_vz[:, 1]\n",
    "        del_bx = tape0.gradient(bx, xt)\n",
    "        dbx_dx = del_bx[:, 0]\n",
    "        dbx_dt = del_bx[:, 1]\n",
    "        del_by = tape0.gradient(by, xt)\n",
    "        dby_dx = del_by[:, 0]\n",
    "        dby_dt = del_by[:, 1]\n",
    "        del_bz = tape0.gradient(bz, xt)\n",
    "        dbz_dx = del_bz[:, 0]\n",
    "        dbz_dt = del_bz[:, 1]\n",
    "\n",
    "        # Compute the estimates of the differential equations.\n",
    "        G1 = pde1(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt)\n",
    "        G2 = pde2(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt)\n",
    "        G3 = pde3(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt)\n",
    "        G4 = pde4(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt)\n",
    "        G5 = pde5(x, t, rho, vx, vy, vz, bx, by, bz, dvx_dx, dvx_dt, dvy_dx, dvy_dt, dvz_dx, dvz_dt, dbx_dx, dbx_dt, dby_dx, dby_dt, dbz_dx, dbz_dt)\n",
    "\n",
    "        # Compute the loss functions.\n",
    "        L1 = tf.math.sqrt(tf.reduce_sum(G1**2)/n_train)\n",
    "        L2 = tf.math.sqrt(tf.reduce_sum(G2**2)/n_train)\n",
    "        L3 = tf.math.sqrt(tf.reduce_sum(G3**2)/n_train)\n",
    "        L4 = tf.math.sqrt(tf.reduce_sum(G4**2)/n_train)\n",
    "        L5 = tf.math.sqrt(tf.reduce_sum(G5**2)/n_train)\n",
    "        L = L1 + L2 + L3 + L4 + L5\n",
    "\n",
    "    # Save the current losses.\n",
    "    losses1.append(L1.numpy())\n",
    "    losses2.append(L2.numpy())\n",
    "    losses3.append(L3.numpy())\n",
    "    losses4.append(L4.numpy())\n",
    "    losses5.append(L5.numpy())\n",
    "    losses.append(L.numpy())\n",
    "\n",
    "    # Check for convergence.\n",
    "    if epoch > 10:\n",
    "        loss_delta = losses[-1] - losses[-2]\n",
    "        if abs(loss_delta) <= tol:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    # Compute the gradient of the loss function wrt the network parameters.\n",
    "    pgrad_rho = tape1.gradient(L, model_rho.trainable_variables)\n",
    "    pgrad_vx = tape1.gradient(L, model_vx.trainable_variables)\n",
    "    pgrad_vy = tape1.gradient(L, model_vy.trainable_variables)\n",
    "    pgrad_vz = tape1.gradient(L, model_vz.trainable_variables)\n",
    "    pgrad_bx = tape1.gradient(L, model_bx.trainable_variables)\n",
    "    pgrad_by = tape1.gradient(L, model_by.trainable_variables)\n",
    "    pgrad_bz = tape1.gradient(L, model_bz.trainable_variables)\n",
    "\n",
    "    # Save the parameters used in this epoch.\n",
    "    phist_rho.append(\n",
    "        np.hstack(\n",
    "            (model_rho.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_rho.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_rho.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_vx.append(\n",
    "        np.hstack(\n",
    "            (model_vx.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_vx.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_vx.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_vy.append(\n",
    "        np.hstack(\n",
    "            (model_vy.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_vy.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_vy.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_vz.append(\n",
    "        np.hstack(\n",
    "            (model_vz.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_vz.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_vz.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_bx.append(\n",
    "        np.hstack(\n",
    "            (model_bx.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_bx.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_bx.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_by.append(\n",
    "        np.hstack(\n",
    "            (model_by.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_by.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_by.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "    phist_bz.append(\n",
    "        np.hstack(\n",
    "            (model_bz.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "             model_bz.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "             model_bz.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update the parameters for this epoch.\n",
    "    optimizer_rho.apply_gradients(zip(pgrad_rho, model_rho.trainable_variables))\n",
    "    optimizer_vx.apply_gradients(zip(pgrad_vx, model_vx.trainable_variables))\n",
    "    optimizer_vy.apply_gradients(zip(pgrad_vy, model_vy.trainable_variables))\n",
    "    optimizer_vz.apply_gradients(zip(pgrad_vz, model_vz.trainable_variables))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        # print(\"Ending epoch %s, loss functions = (%f, %f, %f)\" % (epoch, L1.numpy(), L2.numpy(), L.numpy()))\n",
    "        print(\"Ending epoch %s.\" % epoch)\n",
    "\n",
    "# Save the parameters used in the last epoch.\n",
    "phist_rho.append(\n",
    "    np.hstack(\n",
    "        (model_rho.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_rho.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_rho.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_vx.append(\n",
    "    np.hstack(\n",
    "        (model_vx.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_vx.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_vx.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_vy.append(\n",
    "    np.hstack(\n",
    "        (model_vy.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_vy.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_vy.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_vz.append(\n",
    "    np.hstack(\n",
    "        (model_vz.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_vz.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_vz.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_bx.append(\n",
    "    np.hstack(\n",
    "        (model_bx.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_bx.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_bx.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_by.append(\n",
    "    np.hstack(\n",
    "        (model_by.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_by.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_by.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "phist_bz.append(\n",
    "    np.hstack(\n",
    "        (model_bz.trainable_variables[0].numpy().reshape((2*H,)),    # w (2, H) matrix -> (2H,) row vector\n",
    "         model_bz.trainable_variables[1].numpy(),       # u (H,) row vector\n",
    "         model_bz.trainable_variables[2][:, 0].numpy()) # v (H, 1) column vector\n",
    "    )\n",
    ")\n",
    "\n",
    "n_epochs = epoch + 1\n",
    "\n",
    "t_stop = datetime.datetime.now()\n",
    "print(\"Training stopped at\", t_stop)\n",
    "t_elapsed = t_stop - t_start\n",
    "print(\"Total training time was %s seconds.\" % t_elapsed.total_seconds())\n",
    "print(\"Epochs: %d\" % n_epochs)\n",
    "# print(\"Final value of loss function: %f\" % losses[-1])\n",
    "print(\"converged = %s\" % converged)\n",
    "\n",
    "# Save the parameter histories.\n",
    "np.savetxt(os.path.join(output_dir, 'phist_rho.dat'), np.array(phist_rho))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_vx.dat'), np.array(phist_vx))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_vy.dat'), np.array(phist_vy))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_vz.dat'), np.array(phist_vz))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_bx.dat'), np.array(phist_bx))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_by.dat'), np.array(phist_by))\n",
    "np.savetxt(os.path.join(output_dir, 'phist_bz.dat'), np.array(phist_bz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51c58b2f-0cfa-458d-b52c-68cd600404c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgrad_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b13d0-1215-4ff7-87ba-8209e5442127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
